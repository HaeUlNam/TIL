## 진행 서적

- 핸즈온 머신러닝: 전통적인 머신러닝 이론과 딥러닝 이론 등이 자세하게 설명되어 있어 좋다.

## Chapter01

### 머신러닝이란?

- 이사 사무엘,1959: 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야

ex) 스팸메일 필터링

### 왜 머신러닝을 사용하는가?

- 스팸메일 필터링을 사람이 직접 코딩한다면 각 패턴(ex) 무료, 공짜!)을 발견하고 스팸으로 분류하는 프로그램을 작성하고 성능이 나올 때까지 진행.
  * rule-based라고 한다.
  * 생각보다 복잡하고, 규칙이 계속 생기고... 유지보수가 어렵다.
  * 사실 이러한 rule을 만드는 것이 어렵다. 전문지식을 필요로 한다. ex) 약물 패턴,
- 머신러닝은 스팸으로부터 자주 나오는 패턴들을 스스로 찾고 학습한다. 이로서 프로그램은 간결해지고 유지보수하기 쉽고, 대부분 정확도가 더 높다.
  * 사용하는 단어가 많이 변하기에 사람이 직접하면 이를 적용하기 굉장히 어렵고, 머신러닝으로 하면 바뀐 단어를 기준으로 저절로 catch
- 머신러닝을 적용하면 사람이 이해하기 어려운 데이터에 좋다.

### 머신러닝에 좋은 문제들
- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제
- 전통적인 방식으로는 전혀 해결 방법이 없는 복잡한 문제
- 유동적인 환경: 새로운 데이터들이 항상 발생하는 환경
- 복잡한 문제와 대량의 데이터에서 통찰 얻기
  * 선형 회귀, 결정 트리 등을 통해 .....

### 머신러닝 시스템의 분류
- 사람이 가이드를 해서 훈련하는지 ex) 지도, 비지도, 준지도, 강화 학습
- 실시간으로 점진적인 학습을 하는지 아닌지 ex) 온라인 학습, 배치 학습
  * 온라인 학습은 좀 위험한 부분도 있다. 갑자기 어느 순간에 잘못된 데이터를 학습할 수 있다...
- 사례 기반 학습 vs 모델 기반 학습

### 기계학습 종류
- 지도학습: 알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함. 지도학습에는 분류와 회귀 문제가 존재.
  * 자주 쓰는 모델: KNN, 선형 회귀, 로지스틱 회귀, SVM, 결정 트리와 랜덤 포레스트, 신경망
  * 회귀는 연속되는 값을 예측하는 문제

- 비지도학습: 훈련 데이터에 레이블이 없습니다. 시스템이 아무런 도움 없이 학습.
  * 자주 쓰는 모델: 군집, 시각화와 차원 축소, 연관 규칙 학습

- 준지도학습: 어떤 알고리즘은 레이블이 일부만 있는 데이터도 다룰 수 있습니다.
  * 똑같은 사람이 나오는 사진이 여러개 있다면, 하나의 사진만 라벨링해주면 다른 데이터도 라벨링이 가능하다.

- 강화학습: 학습하는 시스템을 에이전트라고 부르며 환경을 관찰하여 행동을 실행하고 그 결과로 보상을 받습니다.
  * 게임에 좀 맞다. rule와 상황을 만들어야 하는게 어렵다.

### 머신러닝의 주요 도전 과제

- 충분하지 않은 양의 훈련 데이터
  * 알고리즘 개발과 질 좋은 데이터 만드는 것 사이의 트레이드오프를 생각해봐야 한다.
  * 훈련 데이터를 추가로 모으는 것은 쉬운일은 아니기에 알고리즘을 무시하지 말자.
- 대표성 없는 훈련데이터
  * 대부분의 기계학습 문제는 예측. 학습하지 않은 새로운 데이터에 대해 좋은 성능을 보여야 하는데, 이를 위해선 학습한 데이터를
  일반화를 잘해야 한다.
  ![스크린샷 2020-04-01 오후 8 17 58](https://user-images.githubusercontent.com/26040955/78131340-e1f20c00-7455-11ea-84b4-da2f9b6ec5ea.png)
  * 내가 뽑은 데이터가 앞으로 들어올 데이터들을 잘 대표하는지 봐야한다. 그림에서 노르웨이가 만족도가 더 위에 있다면 일반화를
 잘하지 못한 것이라고 할 수 있다.
  * 확률과 통계가 이런 방법론에 대해 공부하는 학문이라서, 이를 공부해보면 앞으로의 데이터들에 대해 일반화를 잘하는지 안하는지
  알 수 있다.
- 과대적합(오버피팅): 모델이 훈련 데이터에 너무 잘 맞지만, 일반성이 떨어짐을 의미
  * 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생하기에, 파라미터 수가 적은 모델을 선택하거나 훈련 데이터에 있는 
  특성 수를 줄이거나, 모델에 제약을 가하여 단순화시킨다. 또한, 데이터를 더 모아서 해결.
  * 좌측이 오버피팅이다.
  ![스크린샷 2020-04-01 오후 8 26 18](https://user-images.githubusercontent.com/26040955/78132074-0c909480-7457-11ea-94e1-3a8a2d2bac9f.png)

### 테스트와 검증

- 학습한 것을 테스트하는 것은 신뢰성이 없다. 따라서 학습하지 않은 데이터로 테스트를 해야 한다. 보통 일정 비율로 학습 데이터와 
테스트 데이터를 나누어 테스트.
  * cross validation: 테스트 데이터를 한번만 하는 게 아니라, 바꾸면서 진행.
  * 일정 비율은 휴리스틱하게 사람이 직접 지정하는데.. 데이터가 많으면 테스트 데이터 비중을 높일 수 있다.(case마다 다르지만 보통 
  20퍼?)
  * Train, Validation, Test: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7
  
  
  
